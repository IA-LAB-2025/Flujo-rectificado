{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOCQpIzwaq6Vr4BgUhYtTF4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Qt6PSuzrBaMX"},"outputs":[],"source":["import tarfile\n","import zipfile\n","import os\n","import random\n","from PIL import Image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, TensorDataset\n","from tqdm import tqdm\n","#from models.model import ConNet, Rectifiedflow\n","#from train.train_rectified_flow import train_rectified_flow\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["#Cargamos las rutas de los archivos .npy donde se encuentran nuestros datos\n","\n","##################\n","ruta_pi_1 = 'ruta'\n","ruta_pi_0 = 'ruta'\n","##################\n","pi_1_np = np.load(ruta_pi_1)\n","pi_0_np = np.load(ruta_pi_0)\n","idx = 5\n","\n","#Verificamos el rango de valores\n","img_array = pi_1_np[idx]\n","print(img_array.shape)\n","print(img_array.dtype)\n","print(img_array.min(), img_array.max())\n","\n","# Visualizamos de acuerdo a idx\n","plt.figure(figsize=(6, 6))\n","plt.subplot(1, 2, 1)\n","plt.imshow(pi_1_np[idx])\n","plt.axis('off')\n","plt.title(f'Famosos {idx}')\n","plt.subplot(1, 2, 2)\n","plt.imshow(pi_0_np[idx])\n","plt.axis('off')\n","plt.title(f'Caricaturas {idx}')\n","plt.show()"],"metadata":{"id":"o9nPLG7zBk3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =========================\n","# 2. Separar train / val\n","# =========================\n","pi0_train, pi0_val, pi1_train, pi1_val = train_test_split(\n","    pi_0_np, pi_1_np, test_size=0.2, random_state=42\n",")\n","\n","# Convertir a tensores y permutar a (N,C,H,W)\n","\n","#Podemos usar los diferentes datos para visualizar las trayectorias, sólo hay\n","#que eliminar el comentario y ajustarlo a esa variable\n","x0_train = torch.tensor(pi0_train, dtype=torch.float32).permute(0,3,1,2)\n","#x1_train = torch.tensor(pi1_train, dtype=torch.float32).permute(0,3,1,2)\n","##x0_val   = torch.tensor(pi0_val, dtype=torch.float32).permute(0,3,1,2)\n","#x1_val   = torch.tensor(pi1_val, dtype=torch.float32).permute(0,3,1,2)\n"],"metadata":{"id":"g6IbLQLiCFB9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ConNet(nn.Module):\n","    '''Convolutional Neural Network for image processing with time conditioning.'''\n","    def __init__(self, in_channels=3, hidden_channels=64, out_channels=3):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels + 1, hidden_channels, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(hidden_channels, out_channels, kernel_size=3, padding=1)\n","        self.act = nn.ReLU()\n","\n","    def forward(self, x_input, t):\n","        batch_size, _, H, W = x_input.shape\n","        t_expanded = t.view(batch_size, 1, 1, 1).expand(-1, 1, H, W)\n","        x = torch.cat([x_input, t_expanded], dim=1)\n","\n","        x = self.act(self.conv1(x))\n","        x = self.act(self.conv2(x))\n","        x = self.conv3(x)\n","        return x\n","\n","class Rectifiedflow():\n","    def __init__(self,model=None, num_steps=100):\n","\n","        self.model = model # Aquí pasas una instancia de ConvNet\n","        self.N = num_steps # Pasos de integración (Euler)\n","\n","    def get_train_tuple(self, z0=None, z1=None):\n","        # z0, z1: [batch_size, 3, 64, 64]\n","        t = torch.rand((z1.shape[0],1),device=z1.device) # [batch_size, 1]\n","        # Interpolación entre z0 y z1 → [batch_size, 3, 64, 64]\n","        z_t = t[:, None, None, None] * z1 + (1. - t[:, None, None, None]) * z0\n","        target = z1 - z0  # Lo que debe aprender\n","        return z_t, t, target  # t sigue siendo [batch_size, 1]\n","\n","    @torch.no_grad()\n","    def sample_ode(self, z0=None, N=None):\n","        \"\"\"\n","        z0: [batch_size, 3, 64, 64]\n","        N: número de pasos (si no se pasa, usa self.N)\n","        \"\"\"\n","        if N is None:\n","            N = self.N\n","\n","        dt = 1. / N\n","        traj = []\n","        z = z0.detach().clone()\n","        batch_size = z.shape[0]\n","\n","        traj.append(z.clone())\n","\n","        for i in range(N):\n","            t = torch.ones((batch_size, 1), device=z.device) * (i / N)\n","            pred = self.model(z, t)  # [batch_size, 3, 64, 64]\n","            z = z + pred * dt\n","            traj.append(z.clone())\n","\n","        return traj  # lista de [batch_size, 3, 64, 64]"],"metadata":{"id":"x7pw9b7mCXev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Cargamos el modelo a revisar sus predicciones\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model = ConNet().to(device)\n","ruta = 'ruta' #POner ruta del modelo\n","model.load_state_dict(torch.load(ruta, map_location=device))\n","model.eval()\n","rectified_flow = Rectifiedflow(model=model, num_steps=100)"],"metadata":{"id":"PHS_unNsCbQV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#////////////////////////////////////////////////////////////#\n","# No es necesario que esté dentro del ciclo for, para no gastar RAM\n","flat_pi1 = pi_1_np.reshape(pi_1_np.shape[0], -1) #Se aplanan las caricaturas\n","flat_pi0 = pi_0_np.reshape(pi_0_np.shape[0], -1) #Se aplanan los famosos\n","dic_Train = {}\n","#////////////////////////////////////////////////////////////#\n","# Concatenamos los conjuntos base\n","X_base = np.vstack((flat_pi1, flat_pi0))\n","\n","# Entrenamos el PCA en esos datos\n","pca = PCA(n_components=2, random_state=42)\n","pca.fit(X_base)  # Aquí se define el espacio latente común"],"metadata":{"id":"GVCuPobJCj7w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Creación de diccionario de las trayectorias\n","def dicc_trayecto(Datos):\n","  trayetorias_dicc = {}\n","  for k in range(len(Datos)):\n","      z0 = Datos[k:k+1].to(device)\n","      with torch.no_grad():\n","           tray = rectified_flow.sample_ode(z0)\n","\n","  # Convertir a numpy para graficar o analizar\n","      trajectory_imgs = []\n","      for step_img in tray:\n","          img = step_img.squeeze().cpu().permute(1, 2, 0).numpy()\n","          img = np.clip(img, 0, 1)  # Asegura valores válidos\n","          trajectory_imgs.append(img)\n","      trayetorias_dicc[str(k)] = trajectory_imgs\n","  return trayetorias_dicc\n","\n","\n","### Creación la definición del aplanamiento de las imagenes\n","def aplanamiento(DIccionario):\n","    flat_inter2_list = []  # Aquí guardamos las imagenes aplanados\n","    #Una vez que construimos los datos, aplanamos los datos del diccionario\n","    for j in range(0,5):\n","        # Accede a las imágenes de la clave j, aplana y agrega\n","        flatten_imgs = [img.flatten() for img in Diccionario[str(j)]]\n","        flat_inter2_list.extend(flatten_imgs)  # Agrega todos a la lista\n","\n","\n","    # Convierte la lista de arrays planos en un array de NumPy\n","    flat_inter2 = np.array(flat_inter2_list)\n","    # Combinamos todo verticalmente\n","    X_total = np.vstack((flat_pi1, flat_pi0, flat_inter2))\n","\n","    return [X_total,flat_inter2.shape[0]]\n","\n","#Proyectamos los datos en el espacio latente\n","X_pi0_proj = pca.transform(flat_pi0)\n","X_pi1_proj = pca.transform(flat_pi1)"],"metadata":{"id":"AR4_kxB1Cn88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dic_Train = {}  # Aquí guardarás las trayectorias proyectadas\n","Numero_imagenes = x0_train.shape[0]\n","m = int(Numero_imagenes/5)\n","for k in range(m):\n","    Datos = x0_train[5*k:5*(k+1),:,:,:]\n","    Diccionario = dicc_trayecto(Datos)  # Genera trayectorias de 5 imágenes\n","\n","    # Aplana las trayectorias del diccionario\n","    flat_inter2_list = []\n","    for j in range(5):\n","        flatten_imgs = [img.flatten() for img in Diccionario[str(j)]]\n","        flat_inter2_list.extend(flatten_imgs)\n","    flat_inter2 = np.array(flat_inter2_list)\n","\n","    # Proyecta con el PCA previamente entrenado\n","    flat_inter2_proj = pca.transform(flat_inter2)\n","\n","    # Guarda las trayectorias proyectadas en el diccionario\n","    for j in range(5):\n","        start = j * 101\n","        end = (j + 1) * 101\n","        dic_Train[str(k*5 + j)] = flat_inter2_proj[start:end, :]\n","\n","    del Diccionario, flat_inter2, flat_inter2_proj"],"metadata":{"id":"WxQRfUjjCyZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(10, 8))\n","\n","# Dibujar los puntos de pi1 y pi0\n","ax.scatter(X_pi1_proj[:, 0], X_pi1_proj[:, 1], alpha=0.3,c='blue', label='$\\pi_1$')\n","ax.scatter(X_pi0_proj[:, 0], X_pi0_proj[:, 1], alpha=0.3, c='red', label='$\\pi_0$')\n","# Colores para diferenciar trayectorias si lo deseas\n","import matplotlib.cm as cm\n","colors = cm.viridis(np.linspace(0, 1, len(dic_Train)))\n","\n","# Dibujar trayectorias\n","for i, (key, traj) in enumerate(dic_Train.items()):\n","    traj = np.array(traj)\n","\n","    # Línea delgada de trayectoria\n","    ax.plot(traj[:, 0], traj[:, 1], '-', linewidth=1, color=colors[i], alpha=0.8)\n","\n","    # Marcar el último punto más fuerte\n","    ax.scatter(traj[-1, 0], traj[-1, 1], color='black', s=30, label='Final' if i == 0 else \"\", zorder=5)\n","\n","    # Opcional: flecha para dirección (último segmento)\n","    if traj.shape[0] >= 2:\n","        ax.annotate(\"\",\n","                    xy=traj[-1], xytext=traj[-2],\n","                    arrowprops=dict(arrowstyle=\"->\", color=colors[i], lw=1),\n","                    size=8)\n","\n","# Estética del gráfico\n","plt.xlabel(\"PCA dimensión 1\")\n","plt.ylabel(\"PCA dimensión 2\")\n","plt.title(\"Interpolación en espacio PCA junto a los grupos reales reflow_model\")\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"YNj48uQMC2F7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Vamos a visualizar las predicciones que más se acercan a nuestro conjunto objetivo\n","#Vamos a estudiar el conjunto de las caricaturas o nuestra distribución objetivo\n","\n","azul_x = X_pi1_proj[:, 0]\n","azul_y = X_pi1_proj[:, 1]\n","\n","min_x = np.min(azul_x)\n","min_y = np.min(azul_y)\n","\n","\n","#Vamos a recorrrer sobre las proyecciones de las trayectorias en el espacio y vamos a encontrarl\n","#las tryaectorias que están dentro del rango de de la distribución objetivo\n","Imagenes = []\n","for k in range(len(dic_Train)):\n","  #Tomamos la evolución de la k-esima imagen\n","  Evolucion = dic_Train[str(k)]\n","  Eje_x = Evolucion[:,0]\n","  Eje_y = Evolucion[:,1]\n","  A = Eje_y > min_y\n","  B = Eje_x > min_x\n","  Mascara = A & B\n","  if np.sum(Mascara) > 0:\n","    print('La imagen',k,'llega a la región objetivo')\n","    if len(np.where(Mascara)[0]) > 80:\n","       Imagenes.append(k)\n","  #np.where(Mascara)"],"metadata":{"id":"vvpRYny_C61n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","En caso de querer ver las trayectorias diferentes a las que\n","no se encuentran cerca de la región del conjunto objetivo \\pi_1\n","Sólo pon los indices de las imagenes en la lista y quita el comentario\n","también es recomendable si es que la linea anterior no imprimió nada\n","indicativo de que ninguna imagen está cerca de la región objetivo\n","'''\n","#Imagenes = []"],"metadata":{"id":"NGVuJyg4DU30"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Prediciremos estas trayectorias con la red\n","Trayecto_imagenes = {}\n","for k in Imagenes:\n","  Imagen_predecir = x0_train[k:k+1]\n","  z0 = Imagen_predecir.to(device)\n","  with torch.no_grad():\n","       tray = rectified_flow.sample_ode(z0)\n","\n","  trajectory_imgs = []\n","  for step_img in tray:\n","      img = step_img.squeeze().cpu().permute(1, 2, 0).numpy()\n","      img = np.clip(img, 0, 1)  # Asegura valores válidos\n","      trajectory_imgs.append(img)\n","  Trayecto_imagenes[k] = trajectory_imgs"],"metadata":{"id":"vMWbei3-DScx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Visualizamos las trayectorias que entran en la región\n","#de nuestro conjunto objetivo\n","for k in Imagenes:\n","  Coordenadas = dic_Train[str(k)]\n","  plt.plot(Coordenadas[:, 0], Coordenadas[:, 1])\n","\n","plt.scatter(X_pi0_proj[:, 0], X_pi0_proj[:, 1], c='red', s=5, label='π₀')\n","plt.scatter(X_pi1_proj[:, 0], X_pi1_proj[:, 1], c='blue', s=5, label='π1')\n","plt.legend()\n","plt.ylim(min_y,100)\n","plt.xlim(min_x,150)\n","plt.title(\"Trayectorias proyectadas con PCA entrenado\")\n","plt.show()"],"metadata":{"id":"91c-zFcBD4Ue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Graficamos la imagen inicial y la final de las trayectorias\n","#que se encunetrna más cerca de la región del conjunto objetivo.\n","for k in Trayecto_imagenes:\n","    trayectoria = Trayecto_imagenes[k]\n","    imagen_inicial = trayectoria[0]     # Primer paso\n","    imagen_final = trayectoria[-1]      # Último paso\n","\n","    fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n","\n","    axs[0].imshow(np.clip(imagen_inicial, 0, 1))\n","    axs[0].set_title(f\"Imagen inicial (ID: {k})\")\n","    axs[0].axis('off')\n","\n","    axs[1].imshow(np.clip(imagen_final, 0, 1))\n","    axs[1].set_title(\"Imagen generada\")\n","    axs[1].axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n"],"metadata":{"id":"1g0W97jrEEpn"},"execution_count":null,"outputs":[]}]}